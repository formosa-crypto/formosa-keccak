// DEPENDENCIES
// require "keccak1600_avx2.jinc"
// param int ASIZE = 1002;
// param int RATE8

require "../common/subreadwrite_ASIZE.jinc"

/*
   ONE-SHOT (FIXED-SIZE) ARRAY ABSORB
   ==================================
*/

inline fn __addstate_avx2
( reg u256[7] st
, inline int AT
, reg const ptr u8[ASIZE] buf
, reg ui64 offset
, inline int LEN
, inline int TRAILB
) -> reg u256[7] /* st */
   , inline int  /* AT */
   , reg ui64    /* offset */
/*
requires{0<= offset && 0<= LEN && offset + LEN <= ASIZE && is_arr_init(buf,offset,LEN) && is_arr_init(st,0,7*32) && LEN <= 200}
requires{0 <= TRAILB && TRAILB < 256}
ensures{is_arr_init(result.0,0,7*32) && result.1 == offset + LEN}
*/
{
  reg u64 t64_1, t64_2, t64_3, t64_4, t64_5 ;
  reg u256 r0, r1, r2, r3, r4, r5, r6;
  reg u128 t128_0, t128_1, t128_2;
  inline int DELTA;

  DELTA = 0;

  DELTA, LEN, TRAILB, AT, t64_1 = __a_ilen_read_upto8_at(buf, offset, DELTA, LEN, TRAILB, 0, AT);
  t128_0 = (128u) t64_1;
  r0 = #VPBROADCAST_4u64(t128_0);
  st[0] ^= r0;

  DELTA, LEN, TRAILB, AT, r1 = __a_ilen_read_upto32_at(buf, offset, DELTA, LEN, TRAILB, 8, AT);
  st[1] ^= r1;

  DELTA, LEN, TRAILB, AT, t64_2 = __a_ilen_read_upto8_at(buf,offset, DELTA,  LEN, TRAILB, 40, AT);
  t128_1 = (128u) t64_2;
  t128_2 = #set0_128();
  if ( 0 < LEN || TRAILB != 0) {
    DELTA, LEN, TRAILB, AT, r3 = __a_ilen_read_upto32_at(buf, offset, DELTA, LEN, TRAILB, 48, AT);
    DELTA, LEN, TRAILB, AT, t64_3 = __a_ilen_read_upto8_at(buf, offset, DELTA, LEN, TRAILB, 80, AT);
    t128_2 = (128u) t64_3;
    DELTA, LEN, TRAILB, AT, r4 = __a_ilen_read_upto32_at(buf, offset, DELTA, LEN, TRAILB, 88, AT);
    DELTA, LEN, TRAILB, AT, t64_4 = __a_ilen_read_upto8_at(buf, offset, DELTA, LEN, TRAILB, 120, AT);
    t128_1 = #VPINSR_2u64(t128_1, t64_4, 1);
    DELTA, LEN, TRAILB, AT, r5 = __a_ilen_read_upto32_at(buf, offset, DELTA, LEN, TRAILB, 128, AT);
    DELTA, LEN, TRAILB, AT, t64_5 = __a_ilen_read_upto8_at(buf, offset, DELTA, LEN, TRAILB, 160, AT);
    t128_2 = #VPINSR_2u64(t128_2, t64_5, 1);
    DELTA, LEN, TRAILB, AT, r6 = __a_ilen_read_upto32_at(buf, offset, DELTA, LEN, TRAILB, 168, AT);
    st = __addstate_r3456_avx2( st, r3, r4, r5, r6);
  }
  r2 = (2u128)[t128_1, t128_2];
  st[2] ^= r2;
  offset += DELTA;
  return st, AT, offset;
}

inline fn __absorb_avx2
( reg u256[7] st
, inline int AT
, reg const ptr u8[ASIZE] buf
, inline int TRAILB /* closes state if !=0 (i.e. adds trailbyte and padding) */
) -> reg u256[7] /* st */
   , inline int  /* AT */
/*
requires{0<= offset && 0<= LEN && offset + LEN <= ASIZE && 0<RATE8 && RATE8 < 200 &&
         is_arr_init(buf,offset,LEN) && is_arr_init(st,0,7*32)}
requires{0 <= TRAILB && TRAILB < 256}
ensures{is_arr_init(result.0,0,7*32)}
*/
{
  reg ui64 offset, i;
  inline int LEN, ITERS;

  offset = 0;
  LEN = ASIZE;  

  if ( AT+LEN >= RATE8 ) { // more than one block...
    st, _, offset = __addstate_avx2(st, AT, buf, offset, RATE8-AT, 0);
    LEN = LEN - (RATE8-AT);
    AT = 0;
    st = _keccakf1600_avx2(st);
    ITERS = LEN/RATE8;
    i = 0;
    while ( i < ITERS ) {
      st, _, offset = __addstate_avx2(st, 0, buf, offset, RATE8, 0);
      st = _keccakf1600_avx2(st);
      i += 1;
    }
    LEN = LEN % RATE8;
  }
  st, AT, _ = __addstate_avx2(st, AT, buf, offset, LEN, TRAILB);
  if (TRAILB!=0) { st = __addratebit_avx2(st, RATE8); }

  return st, AT;
}

/*
   ONE-SHOT (FIXED-SIZE) ARRAY SQUEEZE
   ====================================
*/

inline fn __dumpstate_avx2
( reg mut ptr u8[ASIZE] buf
, reg ui64 offset
, inline int LEN
, reg u256[7] st
) -> reg ptr u8[ASIZE] /* buf */
   , reg ui64 /* offset */
/*
requires{0<= offset && 0<= LEN && offset + LEN <= ASIZE && is_arr_init(st,0,7*32) && LEN <= 200}
ensures{result.1 == offset + LEN}
ensures { \all (k \in 0:ASIZE) (is_arr_init(result.0,k,1) == (is_arr_init(buf,k,1) || (offset <= k && k< offset + LEN)))}
*/
{
  reg u64 t;
  reg u128 t128_0, t128_1;
  reg u256 t256_0, t256_1, t256_2, t256_3, t256_4;
  inline int DELTA;

  DELTA = 0;

  // reg0
  if (8 <= LEN) {
    buf, DELTA, _ = __a_ilen_write_upto32(buf, offset, DELTA, 8, st[0]);
    LEN -= 8;
  } else {
    buf, DELTA, LEN = __a_ilen_write_upto32(buf, offset, DELTA, LEN, st[0]);
  }

  // reg1
  buf, DELTA, LEN = __a_ilen_write_upto32(buf, offset, DELTA, LEN, st[1]);

  // reg2 (5)
  if (0 < LEN) {
    t128_0 = (128u) st[2];
    t128_1 = #VEXTRACTI128(st[2], 1);
    t = (64u) t128_1;
    buf, DELTA, LEN = __a_ilen_write_upto8(buf, offset, DELTA, LEN, t);
    t128_1 = #VPUNPCKH_2u64(t128_1, t128_1);

    if (0 < LEN) { // regs 3,4,5,6
      // [ 16, 7, 8, 19 ]
      t256_0 = #VPBLEND_8u32(st[3], st[4], (8u1)[1,1,1,1,0,0,0,0]);
      // [ 11, 22, 23, 14 ]
      t256_1 = #VPBLEND_8u32(st[4], st[3], (8u1)[1,1,1,1,0,0,0,0]);
      // [ 21, 17, 18, 24 ]
      t256_2 = #VPBLEND_8u32(st[5], st[6], (8u1)[1,1,1,1,0,0,0,0]);
      // [ 6, 12, 13, 9 ]
      t256_3 = #VPBLEND_8u32(st[6], st[5], (8u1)[1,1,1,1,0,0,0,0]);

      // [ 6, 7, 8, 9 ]
      t256_4 = #VPBLEND_8u32(t256_0, t256_3, (8u1)[1,1,0,0,0,0,1,1]);
      buf, DELTA, LEN = __a_ilen_write_upto32(buf, offset, DELTA, LEN, t256_4);
      
      // reg2 (10)
      if (0 < LEN) {
	t = (64u) t128_0;
	buf, DELTA, LEN = __a_ilen_write_upto8(buf, offset, DELTA, LEN, t);
	t128_0 = #VPUNPCKH_2u64(t128_0, t128_0);
      }

      if (0 < LEN) { // [ 11, 12, 13, 14 ]
	t256_4 = #VPBLEND_8u32(t256_3, t256_1, (8u1)[1,1,0,0,0,0,1,1]);
	buf, DELTA, LEN = __a_ilen_write_upto32(buf, offset, DELTA, LEN, t256_4);
      }

      // reg2 (15)
      if (0 < LEN) {
	t = (64u) t128_1;
	buf, DELTA, LEN = __a_ilen_write_upto8(buf, offset, DELTA, LEN, t);
      }

      if (0 < LEN) { // [ 16, 17, 18, 19 ]
	t256_4 = #VPBLEND_8u32(t256_2, t256_0, (8u1)[1,1,0,0,0,0,1,1]);
	buf, DELTA, LEN = __a_ilen_write_upto32(buf, offset, DELTA, LEN, t256_4);
      }

      // reg2 (20)
      if (0 < LEN) {
	t = (64u) t128_0;
	buf, DELTA, LEN = __a_ilen_write_upto8(buf, offset, DELTA, LEN, t);
      }

      if (0 < LEN) { // [ 21, 22, 23, 24 ]
	t256_4 = #VPBLEND_8u32(t256_1, t256_2, (8u1)[1,1,0,0,0,0,1,1]);
	buf, DELTA, LEN = __a_ilen_write_upto32(buf, offset, DELTA, LEN, t256_4);
      }
    }
  }
  offset += DELTA;
  return buf, offset;
}

inline fn __squeeze_avx2
( reg mut ptr u8[ASIZE] buf
, reg u256[7] st
) -> reg ptr u8[ASIZE] /* buf */
   , reg u256[7] /* st */
/*
requires{0<= offset && 0<= LEN && 0< RATE8 && RATE8 < 200 && offset + LEN <= ASIZE && is_arr_init(st,0,32*7)}
ensures{is_arr_init(result.1,0,32*7)} 
ensures { \all (k \in 0:ASIZE) (is_arr_init(result.0,k,1) == (is_arr_init(buf,k,1) || (offset <= k && k< offset + LEN)))}
*/
{
  reg ui64 i, offset;
  inline int LEN, ITERS, LO;

  offset = 0;
  LEN = ASIZE;
  ITERS = LEN/RATE8;
  LO = LEN%RATE8;
  if (0 < LEN) {
    if (0 < ITERS) {
      i = 0;
      while (i < ITERS) {
        st = _keccakf1600_avx2(st);
        buf, offset = __dumpstate_avx2(buf, offset, RATE8, st);
        i += 1;
      }
    }
    if (0 < LO) {
        st = _keccakf1600_avx2(st);
        buf, offset = __dumpstate_avx2(buf, offset, LO, st);
    }
  }
  return buf, st;
}

