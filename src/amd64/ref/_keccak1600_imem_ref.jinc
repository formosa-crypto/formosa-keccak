/** IMPORTANT:
  This file is expected to be loaded with one of the following files
require "keccak1600_ref.jinc"	// without BMI1 support
require "keccak1600_bmi1.jinc"	// with BMI1 support
*/

require "../common/subreadwrite_imem.jinc"


/*
   INCREMENTAL (FIXED-SIZE) MEMORY ABSORB
   ======================================
*/


inline fn __addstate_imem_ref
( reg mut ptr u64[25] st
, inline int AT /* bytes (0 <= AT < 200) */
, reg ui64 buf
, inline int LEN
, inline int TRAILB
) -> reg ptr u64[25] /* st */
   , inline int /* AT */
   , reg ui64 /* buf */
/* safety */ requires
 { 0 <= LEN &&  0<=AT  && AT < 200 && AT + LEN + (TRAILB != 0 ? 1 : 0) < 200 
   && is_mem_init((64u) buf,LEN) && is_arr_init(st,0,25*8)
   && 0 <= TRAILB && TRAILB < 256
 }
/* safety */ ensures
 { is_arr_init(result.0,0,25*8) && result.1 == AT + LEN + (TRAILB != 0 ? 1 : 0) && result.2 == buf + LEN
 }
{
  inline int LO, ALL;
  reg ui64 at;
  reg u64 t;

  ALL = AT+LEN; // total bytes to process (excluding trail byte, if !=0)
  LO = AT % 8; // leftover bytes
  at = (AT / 8); // current pstate position (referencing u64 words)

  if ( 0 < LO ) { // process first word...
    if ( LO+LEN < 8) { // ...not enough to fill a word (just update it)
      if ( TRAILB != 0 ) { ALL += 1; }
      buf, _, _, t = __mread_subu64(buf, LEN, TRAILB);
      t <<= 8*LO;
      t ^= st[at];
      st[at] = t;
      LO = 0;
      AT = 0;
      LEN = 0;
      TRAILB = 0;
    } else { // process first word
      if ( 8 <= LEN ) {
	t = (u64)[(64u)buf];
	buf += 8-LO;
      } else {
        buf, _, _, t = __mread_subu64(buf, 8-LO, TRAILB);
      }
      LEN -= 8-LO;
      AT += 8-LO;
      t <<= 8*LO;
      t ^= st[at];
      st[at] = t;
      at += 1;
    }
  }

  // continue processing remaining bytes
  if (8 <= LEN) {
    while ( at < (AT/8)+(LEN/8)) {
      t = (u64)[(64u)buf];
      buf += 8;
      t ^= st[at];
      st[at] = t;
      at += 1;
    }
    LEN = (AT+LEN) % 8;
  }

  // process last word (possibly closing the state)
  LO = (AT+LEN) % 8;
  if ( 0 < LO || TRAILB != 0 ) {
    buf, _, _, t = __mread_subu64(buf, LO, TRAILB);
    if ( TRAILB != 0 ) { ALL += 1; TRAILB = 0; }
    t ^= st[at];
    st[at] = t;
  }
    
  return st, ALL, buf;
} 

inline fn __absorb_imem_ref
( reg mut ptr u64[25] st
, inline int AT
, reg ui64 buf
, inline int LEN
, inline int RATE8
, inline int TRAILB /* closes state if !=0 (i.e. adds trailbyte and padding) */
) -> reg ptr u64[25] /* st */
   , inline int /* AT */
   , reg ui64 /* buf */
/* safety */ requires
 { 0 <= LEN &&  0<=AT  && AT < RATE8 && AT + LEN + (TRAILB != 0 ? 1 : 0) < 200 && 0 < RATE8 && RATE8 < 200 
   && is_mem_init((64u) buf,LEN) && is_arr_init(st,0,25*8)
   && 0 <= TRAILB && TRAILB < 256
 }
/* safety */ ensures
 { is_arr_init(result.0,0,25*8) && result.1 == AT + LEN + (TRAILB != 0 ? 1 : 0)
 }
{
  reg ui64 i;
  inline int ALL, ITERS;

  ALL = AT + LEN;
  if ( (AT+LEN) < RATE8 ) { // not enough to fill a block!
    st, AT, buf = __addstate_imem_ref(st, AT, buf, LEN, TRAILB);
    if (TRAILB != 0) { // add pstate and closes the state
      st = __addratebit_ref(st, RATE8);
    }
  } else { // at least a block is filled
    if ( AT != 0 ) { // start by filling the first block
      st, _, buf = __addstate_imem_ref(st, AT, buf, RATE8-AT, 0);
      LEN = LEN - (RATE8-AT);
      () = #spill(buf);
      st = _keccakf1600_ref(st);
      () = #unspill(buf);
      AT = 0;
    }

    // continue by processing full blocks
    ITERS = LEN / RATE8; // number of full blocks
    i = 0;
    while ( i < ITERS ) {
      st, _, buf = __addstate_imem_ref(st, 0, buf, RATE8, 0);
      () = #spill(buf,i);
      st = _keccakf1600_ref(st);
      () = #unspill(buf,i);
      i += 1;
    }

    // last incomplete block
    LEN = ALL % RATE8;
    st, AT, buf = __addstate_imem_ref(st, 0, buf, LEN, TRAILB);
    if (TRAILB!=0) { st = __addratebit_ref(st, RATE8); }
  }
  return st, AT, buf;
}

/*
   ONE-SHOT (FIXED-SIZE) MEMORY SQUEEZE
   ====================================
*/
inline fn __dumpstate_imem_ref
( reg ui64 buf
, inline int LEN
, reg const ptr u64[25] st
) -> reg ui64 /* buf */
/* safety */ requires
 { 0 <= LEN &&  is_mem_init((64u) buf,LEN)
   && is_arr_init(st,0,25*32)
 }
/* safety */ ensures
 { result.0 == buf + LEN }
{
  reg ui64 i;
  reg u64 t;

  i = 0;
  while (i < (LEN/8)) {
    t = st[i];
    i += 1;
    (u64)[(64u)buf] = t;
    buf += 8;
  }

  if (0 < LEN%8) {
    t = st[i];
    buf, _ = __mwrite_subu64( buf, LEN%8, t);
  }

  return buf;
}

inline fn __squeeze_imem_ref
( reg ui64 buf
, inline int LEN
, reg mut ptr u64[25] st
, inline int RATE8
) -> reg ui64 /* buf */
   , reg ptr u64[25] /* st */
/* safety */ requires
 { 0 <= LEN && 0 < RATE8 && RATE8 < 200
   && is_mem_init((64u) buf,LEN) && is_arr_init(st,0,25*8)
 }
/* safety */ ensures
 { is_arr_init(result.1,0,25*8) && result.0 == buf + LEN }
{
  reg ui64 i;
  inline int ITERS, LO;

  ITERS = LEN/RATE8;
  LO = LEN%RATE8;
  if (0 < LEN) {
    if (0 < ITERS) {
      i = 0;
      while (i < ITERS) {
	() = #spill(buf,i);
        st = _keccakf1600_ref(st);
	() = #unspill(buf,i);
        buf = __dumpstate_imem_ref(buf, RATE8, st);
        i += 1;
      }
    }
    if (0 < LO) {
	() = #spill(buf);
        st = _keccakf1600_ref(st);
	() = #unspill(buf);
        buf = __dumpstate_imem_ref(buf, LO, st);
    }
  }
  return buf, st;
}
